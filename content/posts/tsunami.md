---
title: "The metaphorical AI shoreline recedes before the Tsunami of late 2024"
date: 2023-07-16T00:30:03Z
draft: true
categories:
  - AI 
image: "cyber-punk-all-seeing-eye.jpeg"
---
2023-07-20 T00:30:03Z

In January I was pretty sure that in two years, most code jobs would be obsolete. In May it was suggested that perhaps they all will switch to kind of content creation or a different type of coding. The senate hearing went well, after an ominous warning from Jeffrey Hinton, who presumably was breing melodramatic before retirement and has just gotten old and isn't the best judge. I would like to second guess myself, but I'm sticking to my guns.

I expected exponential growth, and that was the case with GPT-4. It's way more accurate, and way smarter. It scores in the top 90th percentile of the bar exam and most college entrance exams, where 3.5 scored in the bottom 10th. It can tell you why any joke is funny. It now has excellent knowledge of the physical world and spatial reasoning. Give it any list of physical items and it can reason about how to smartly stack them. And then add theory of mind and other emergent properties. 

So the growth in quality as far as depth of reasoning is right on schedule of what I thought. What I didn't expect was the breadth of growth. Dozens of competitors to ChatGPT are starting to gain traction. And even Elon started his own AI dev team called xAI comprised of the best of the best cherry picked from OpenAI and Google.

Research in robotics has skyrocketed. 

AI is popping up in every aspect of software.

Lots of breadth.

But expectations have increased and either more of the same or only incremental improvements are being produced.

So the excitement is decreasing, and so is the level of concern. People are dropping their guard. Some are deciding it's not even a threat.

Even coders who were at first very alarmed while their peers mocked them are now starting to say that AI will not be smart enough to replace the average coder in a long while.

All of this goes to make me want to second guess myself.

But then there is the context window. The context window is how much text the model can process before trailing off. 

In January the OpenAI models would trail off after 3 to 5 pages or about 4000 tokens. Then it went to 6 to 10 pages (8000 tokens) with GPT 4, now it is 25 pages (32,000 tokens) with some of the improved GPT 4 models. In six months the context window increased in size by a factor of 5! 

And now, where this was once rarely spoken of, there is a ton of R and D being done specifically focussed on increasing the context window. So I think it's a safe assumption that the context window, at the very minimum, will increase by a factor of 5 every 6 months. That would be roughly a 4 million token limit for ChatGPT by the end of 2024. 4 million tokens is about 3,000 pages worth of text, the codebases of a dozen or so web apps or desktop apps, or the codebase of an entire linux kernel. And this is a conservative estimate!   

With this, hardware limitations could play a major roll. But consider that Anthropic's Claude 2 is now up to 100k tokens or roughly 75 pages, and Microsoft is already working on an architecture called "Longnet" with the aim of supporting a billion tokens, or, something like 100 thousand pages of text. These are not brute force techniques, but architectural solutions similar to the ***transormer*** which extended the depth of the neural net, but this time with the breadth. So while my projection may seem unrealistic, efforts are already being made towards token capacities several orders of magnitude higher than what I am predicting. 

This in itself will be another shocking leap.

For instance most of the current limitations with LLMs as far as their ability to write software is due to the limitted context window. The model simply can't take all code and documentation relevant to the project into consideration, not to mention all variations of the code that have been tried and all error messages. They fall disappointingly short. But what can you expect with a max limit of 25 pages, and a typical limit of 5?

So I say this lull in AI enthusiasm is like what happens before a tsunami.

People see the competitors creating LLMs of even lower capacity than GPT-4. And they start getting a false sense of job security. 

This is like the receding shoreline.

Deep at sea a tsunami is only a few feet high, but miles long.

The widening context window is like that long shallow wave, sucking out the tide.

Coders are starting to venture out into their respective fields. 

"Oh look, free conent creation." ( a washed up fish, good for eating )

"Oh look, we can put our entire business, including content and images, into dropbox now and smart search it like as if it were google." ( a washed up octopus ).

"Oh look, here's a shortcut to porting python code to c++." ( a path to the jetti where there once was 6 feet of water.)

And then it's gonna be, "Oh cool, Elon says he's almost ready to roll out xAI, and GPT-5 is coming out, we can't wait to see what new conveniences are in store! This could only mean more money." ( a shadow on the horizon. ) 

And then..."Holy crap. This time it actually does build entire websites from the ground up, not just from templates!" ( people grilling all of the washed up fish having a party. ) 

And then..."Oh cool, ChatGPT remembers to give me spanish lessons, at a time more convenient than I could have come up with, when I had forgotten that last week I had resolved to start studying spanish again?!" ( some guy inspecting a whale )

And then..."Daaaaamn, you mean, content creators just say what kind of game they want, add content and deploy it themselves? And this time it's not just click bait saying this?" ( Hey, see the size of that wave way out there? )

And then..."Whoa...I just asked it to make an entire app like photoshop, and it did it in 2 hours." ( Oh shit, it's getting bigger )

And then..."No...way...not only does it make entire websites from the ground up, it makes full blown web apps!" ( Everyone looking toward the horizon. )

And then..."So...what does this mean for our jobs?" ( People starting to backstep. ) 

And then..."Oh shit, the companies had guaranteed job roles alongside the AI, but they can't do that if they themselves go under!" ( Everybody ruuuuuuun! )

Hopefully people see it coming in February of next year and start to prepare.

But such is my prediction for the end of 2024.

I am no expert. And like I said, I would like to hedge my bets here. But that context window is a bitch. And if the models have one more leap in intelligence, or even just in reliability...

